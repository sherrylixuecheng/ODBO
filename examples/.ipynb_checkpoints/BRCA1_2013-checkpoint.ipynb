{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import odbo\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_seed = 8\n",
    "np.random.seed(random_seed)\n",
    "data_test = pd.read_csv('../datasets/BRCA1_2013_98299.csv', sep=',')\n",
    "name_pre, Y_test = np.array(data_test['AACombo']), np.array(data_test['Log2Eratio'])\n",
    "\n",
    "del data_test\n",
    "if os.path.isfile('sele_indices_BRCA1_2013.npy') == True:\n",
    "    sele_indices = np.load('sele_indices_BRCA1_2013.npy')\n",
    "    shuffle_order = np.load('shuffle_order_BRCA1_2013.npy')\n",
    "    name_pre[1:], Y_test[1:] = name_pre[shuffle_order[1:]], Y_test[shuffle_order[1:]]\n",
    "    name = odbo.utils.code_to_array(name_pre)    \n",
    "else:\n",
    "    shuffle_order = np.arange(len(Y_test))\n",
    "    np.random.shuffle(shuffle_order[1:])\n",
    "    np.save('shuffle_order_BRCA1_2013.npy', shuffle_order)\n",
    "    name_pre[1:], Y_test[1:] = name_pre[shuffle_order[1:]], Y_test[shuffle_order[1:]]\n",
    "    name = odbo.utils.code_to_array(name_pre)\n",
    "    sele_indices = odbo.initialization.initial_design(name, least_occurance=np.ones(102),allow_abundance=True,update_method='correlate',verbose=True)\n",
    "    np.save('sele_indices_BRCA1_2013.npy', sele_indices)\n",
    "name_sele, Y_train = name[sele_indices, :], Y_test[sele_indices]\n",
    "ids_keep = np.delete(range(len(Y_test)), sele_indices)\n",
    "name, Y_test = name[ids_keep, :], Y_test[ids_keep]\n",
    "print('Selected initial experiments no. is ', len(Y_train))\n",
    "print('Select max Y: ', Y_train.max(), 'True max Y:', Y_test.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = odbo.featurization.FewFeatureTransform(raw_vars=name_sele, Y=Y_train, method='Avg', mode='hybrid')\n",
    "X_test = feature_model.transform(name)\n",
    "X_train = feature_model.transform(name_sele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the adaptive search space model\n",
    "threshold = Y_train[np.argsort(Y_train)[int(0.95*len(Y_train))]]\n",
    "print(threshold)\n",
    "labels_train = odbo.prescreening.sp_label(X_train, Y_train, thres=threshold)\n",
    "pre_model = odbo.prescreening.XGBOD(eval_metric = 'error', random_state = random_seed)\n",
    "pre_model.fit(X_train, labels_train)\n",
    "pred_labels = pre_model.predict(X_train)\n",
    "labels_test = odbo.prescreening.sp_label(X_test, Y_test, thres=threshold)\n",
    "pred_test_labels = pre_model.predict(X_test)\n",
    "# Plot the confusion matrix to check the accuracy of search space prescreening\n",
    "out_outlier, in_outlier, out_inlier, in_inlier = odbo.plot.plot_cm(labels_test, pred_test_labels, Y_test)\n",
    "print(\"Correct ratio: {0:.3%}\".format((len(out_outlier)+len(in_inlier))/len(labels_test)))\n",
    "print(\"FN ratio: {0:.3%}\".format(len(out_inlier)/len(labels_test)))\n",
    "print(\"FP ratio: {0:.3%}\".format(len(in_outlier)/len(labels_test))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODBO, BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prescreening size:  4047\n",
      "Iter:  0 Current Max:  4.36034523 Test max:  8.9976047\n",
      "Newly added value:  [[-0.7306493]] LEKFKLLAEKMEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQLQAWMREKQSSDH\n",
      "Iter:  1 Current Max:  4.36034523 Test max:  8.9976047\n",
      "Newly added value:  [[5.57920596]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSRTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  2 Current Max:  5.57920596 Test max:  8.9976047\n",
      "Newly added value:  [[5.64384343]] IEKFKLLAEKVEEIVAKNAWAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  3 Current Max:  5.643843426 Test max:  8.9976047\n",
      "Newly added value:  [[8.9976047]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLYSPTDPFTRQILTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  4 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[0.88602206]] LEKFKLLAEKVEEIVAKNARAELDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLYSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  5 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[5.99467638]] LEKFKLLAEKVEEIVAKNAWAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  6 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[3.25641164]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFNRQILTESMLEPVPDLKEQIQAWMREKQSSDH\n",
      "Iter:  7 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[5.17482619]] IEKFKLLAEKVEEIVAKNAWAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  8 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[0.22204498]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSATDPFTREMLTESMLEPVPELKEQIQAWMREKQSSVH\n",
      "Iter:  9 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[-1.39807396]] IEKFKLLAEKVEEIVAKNAWAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESILEPVPELKEQIKAWMREKQSSDH\n",
      "Iter:  10 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[3.96979042]] IEKFKLLAEKVEEIVAKNAWEEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLYSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSRDH\n",
      "Iter:  11 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[3.13995718]] LEKFKLLAEKVEEIAAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSRTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  12 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[2.3153631]] KEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  13 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[6.53013958]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  14 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[-0.12919868]] LETFKLLAEKVEEIVAKNARAEIEYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESMLEPVPKLKEQIQAWMREKQSRDH\n",
      "Iter:  15 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[2.96818116]] LEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVIDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSGDH\n",
      "Iter:  16 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[-0.98119276]] IEKFKLLIEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  17 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[3.79950031]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSGDH\n",
      "Iter:  18 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[4.13784591]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLYSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  19 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[-0.78509709]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  20 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[-2.83018498]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  21 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[-0.6375399]] IEKFKLLAEKVEEIVAKNAWAEIDYSDAPDEFRDPLMDTLLTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  22 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[2.29254033]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSRTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  23 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[3.76508462]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSATDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  24 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[1.2693507]] IEKFKLLAEKVEEIVAKNAWEEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  25 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[4.10031524]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFNRQILTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  26 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[0.12496079]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFNRQMLTESMLERVPELKEQIQAWMREKQSSDH\n",
      "Iter:  27 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[3.59661224]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKPSSDH\n",
      "Iter:  28 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[2.6843882]] LEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFSRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  29 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[2.25513684]] IEKFKLLAEKVEEIVAKNARAELDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLYSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  30 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[5.18953812]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLNSPTDPFTRQMLSESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  31 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[-2.02610519]] LEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQILSESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  32 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[-1.97272409]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  33 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[-2.82462545]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFTRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  34 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[3.01658463]] IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVLDRSIILRHLLYSPTDPFNRQMLSESMLEPVPELKEQIQAWMREKQSSDH\n",
      "Iter:  35 Current Max:  8.9976047 Test max:  7.442611412\n",
      "Newly added value:  [[3.89384156]] IEKFKLLAEKVEEIVAKNAWAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVIDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\n"
     ]
    }
   ],
   "source": [
    "X_train_sele, Y_train_sele = torch.tensor(X_train), torch.tensor(Y_train.reshape(len(Y_train),1))\n",
    "sele_id_test = list(np.where(pred_test_labels == 0)[0])\n",
    "search_name_sele, name_sele_temp = name[sele_id_test, :], name_sele\n",
    "X_test_sele, Y_test_sele = torch.tensor(X_test[sele_id_test, :]), torch.tensor(Y_test[sele_id_test].reshape(len(sele_id_test),1))\n",
    "print(\"Prescreening size: \", len(sele_id_test))\n",
    "\n",
    "## Run BO experiment with robust regression or directly gp\n",
    "l, search_iter = 0, 50\n",
    "batch_size = 1\n",
    "gp_method='robust_regression'\n",
    "failure_count = 0\n",
    "while l < search_iter:\n",
    "    print(\"Iter: \", l, \"Current Max: \", Y_train_sele.max().detach().numpy(), \"Test max: \", Y_test_sele.max().detach().numpy())\n",
    "    top_ids = np.argsort(Y_train_sele.numpy().ravel())[-40-l:]\n",
    "    sele_feat = []\n",
    "    for i in range(X_train_sele.shape[1]):\n",
    "        if (X_train_sele[top_ids,i]-X_train_sele[0,i]).any() !=0:\n",
    "            sele_feat.append(i)\n",
    "    X_sele = X_train_sele[:,sele_feat]\n",
    "    X_test_sele=X_test_sele[:, sele_feat]\n",
    "    X_next, acq_value, next_exp_id = odbo.bo_design(X=X_sele[top_ids, :], Y=Y_train_sele[top_ids], X_pending=X_test_sele, gp_method=gp_method, batch_size=batch_size)\n",
    "    Y_train_sele = torch.cat([Y_train_sele, Y_test_sele[next_exp_id]])\n",
    "    ids_keep = list(np.delete(range(Y_test_sele.shape[0]), next_exp_id))\n",
    "    Y_test_sele = Y_test_sele[ids_keep]\n",
    "    name_sele_temp = np.concatenate((name_sele_temp, search_name_sele[next_exp_id]))\n",
    "    search_name_sele = search_name_sele[ids_keep]\n",
    "    print(\"Newly added value: \", Y_train_sele[-batch_size:].detach().numpy(), ''.join(name_sele_temp[-1, :]))\n",
    "\n",
    "    if Y_train_sele[-batch_size:].detach().numpy().max() > Y_train_sele[:-batch_size].max():\n",
    "        failure_count = 0\n",
    "        feature_model1 = odbo.featurization.FewFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Avg', mode='hybrid')\n",
    "    else:\n",
    "        failure_count = failure_count + 1\n",
    "        if failure_count >= 3:\n",
    "            feature_model1 = odbo.featurization.FewFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Avg', mode='hybrid')\n",
    "        else:\n",
    "            feature_model1 = odbo.featurization.FewFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Max', mode='hybrid')\n",
    "\n",
    "    X_test_sele= torch.tensor(feature_model1.transform(search_name_sele))\n",
    "    X_train_sele = torch.tensor(feature_model1.transform(name_sele_temp))\n",
    "    l = l + 1\n",
    "    \n",
    "np.save('results/BRCA1_2013/BRCA1_2013_ODBO_BO_RobustGP_batch1_{}.npy'.format(random_seed), Y_train_sele)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODBO, TuRBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_sele, Y_train_sele = torch.tensor(X_train), torch.tensor(Y_train.reshape(len(Y_train),1))\n",
    "sele_id_test = list(np.where(pred_test_labels == 0)[0])\n",
    "search_name_sele, name_sele_temp = name[sele_id_test, :], name_sele\n",
    "X_test_sele, Y_test_sele = torch.tensor(X_test[sele_id_test, :]), torch.tensor(Y_test[sele_id_test].reshape(len(sele_id_test),1))\n",
    "print(\"Prescreening size: \", len(sele_id_test))\n",
    "\n",
    "# Run BO experiment with robust regression or directly GP\n",
    "l, search_iter = 0, 50\n",
    "gp_method='gp_regression'\n",
    "tr_length = [3.2]\n",
    "batch_size = 1\n",
    "failure_count = 0\n",
    "state = odbo.turbo.TurboState(dim=X_train_sele.shape[1], batch_size=batch_size, length=tr_length, n_trust_regions=len(tr_length), failure_tolerance = 10)\n",
    "state.best_value = Y_train_sele.max()\n",
    "while l < search_iter:\n",
    "    print(\"Iter: \", l, \"Current Max: \", Y_train_sele.max().detach().numpy(), 'TR length: ', state.length, \"Test max: \", Y_test_sele.max().detach().numpy())\n",
    "    top_ids = np.argsort(Y_train_sele.numpy().ravel())[-40-l:]\n",
    "    sele_feat = []\n",
    "    for i in range(X_train_sele.shape[1]):\n",
    "        if (X_train_sele[top_ids,i]-X_train_sele[0,i]).any() !=0:\n",
    "            sele_feat.append(i)\n",
    "    X_sele = X_train_sele[:,sele_feat]\n",
    "    X_test_sele=X_test_sele[:, sele_feat]\n",
    "    X_next, acq_value, raw_next_exp_id = odbo.turbo_design(state=state, X=X_sele[top_ids, :], Y=Y_train_sele[top_ids], X_pending=X_test_sele, n_trust_regions=len(tr_length), batch_size=batch_size, gp_method=gp_method)\n",
    "    Y_next_m = torch.zeros((len(tr_length), batch_size, 1), device=Y_train_sele.device, dtype=Y_train_sele.dtype)\n",
    "    next_exp_id = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        next_exp_id_m = raw_next_exp_id[:, i]\n",
    "        Y_next_m[:, i, 0], idtoadd = Y_test_sele[next_exp_id_m].reshape(len(tr_length)), next_exp_id_m[np.argmax(Y_test_sele[next_exp_id_m])]\n",
    "        next_exp_id.append(idtoadd)\n",
    "        \n",
    "    Y_train_sele = torch.cat([Y_train_sele, Y_test_sele[next_exp_id]])\n",
    "    ids_keep = list(np.delete(range(Y_test_sele.shape[0]), next_exp_id))\n",
    "    Y_test_sele = Y_test_sele[ids_keep]\n",
    "    name_sele_temp = np.concatenate((name_sele_temp, search_name_sele[next_exp_id]))\n",
    "    search_name_sele = search_name_sele[ids_keep]\n",
    "    print(\"Newly added value: \", Y_train_sele[-batch_size:].detach().numpy(), ''.join(name_sele_temp[-1, :]))\n",
    "    state = odbo.turbo.update_state(state=state, Y_next=Y_next_m)\n",
    "    if Y_train_sele[-batch_size:].detach().numpy().max() > Y_train_sele[:-batch_size].max():\n",
    "        failure_count = 0\n",
    "        feature_model1 = odbo.featurization.FewFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Max', mode='hybrid')\n",
    "    else:\n",
    "        failure_count = failure_count + 1\n",
    "        if failure_count >= 3:\n",
    "            feature_model1 = odbo.featurization.FewFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Avg', mode='hybrid')\n",
    "        else:\n",
    "            feature_model1 = odbo.featurization.FewFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Max', mode='hybrid')\n",
    "    X_test_sele= torch.tensor(feature_model1.transform(search_name_sele))\n",
    "    X_train_sele = torch.tensor(feature_model1.transform(name_sele_temp))\n",
    "\n",
    "    l = l + 1\n",
    "np.save('results/BRCA1_2013/BRCA1_2013_ODBO_TuRBO_GP_batch1_{}.npy'.format(random_seed), Y_train_sele)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Y 2.367313952\n"
     ]
    }
   ],
   "source": [
    "sele_Y = list(np.random.choice(Y_test, 50, replace = False))\n",
    "Y_train_sele = list(Y_train.copy())\n",
    "Y_train_sele.extend(sele_Y)\n",
    "print('Max Y', max(sele_Y))\n",
    "np.save('results/BRCA1_2013/BRCA1_2013_random_{}.npy'.format(random_seed), Y_train_sele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
