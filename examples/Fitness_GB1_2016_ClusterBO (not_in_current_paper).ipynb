{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import odbo\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get initial experiment design (temp using 2016 data, change to other experiments later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "random_seed = 100\n",
    "np.random.seed(random_seed)\n",
    "data_test = pd.read_csv('../datasets/GB1_2016_149361.csv', sep=',')\n",
    "name_pre, Y_test = np.array(data_test['AACombo']), np.array(data_test['Fitness'])\n",
    "print(Y_test[0])\n",
    "shuffle_order = np.arange(len(Y_test))\n",
    "np.random.shuffle(shuffle_order[1:])\n",
    "name_pre[1:], Y_test[1:] = name_pre[shuffle_order[1:]], Y_test[shuffle_order[1:]]\n",
    "name = odbo.utils.code_to_array(name_pre)\n",
    "if os.path.isfile('sele_experiment_GB1_2016.npy') == True:\n",
    "    name_sele = np.load('sele_experiment_GB1_2016.npy')\n",
    "    Y_train = np.load('sele_fitness_GB1_2016.npy')\n",
    "    print('Selected initial experiments no. is ', len(Y_train))\n",
    "else:\n",
    "    # Let each site has 20 AA codes at least show up twice \n",
    "    sele_indices = odbo.initialization.initial_design(name, least_occurance=[2,2,2,2],verbose = False,random_state=random_seed)\n",
    "    # Initial experiments are selected to be name_sele with fitness of Y_sele\n",
    "    name_sele, Y_train = name[sele_indices, :], Y_test[sele_indices]\n",
    "    print('Selected initial experiments no. is ', len(sele_indices))\n",
    "print(Y_train, Y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform AA codes to average fitness feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using average measurement results as features\n",
    "threshold = max(0.05, np.mean(Y_train)-2*np.std(Y_train))\n",
    "print(threshold)\n",
    "feature_model = odbo.featurization.MaxMeasurement(raw_vars=name_sele, Y=Y_train)\n",
    "X_train = feature_model.transform(name_sele)\n",
    "X_test = feature_model.transform(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt search space construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the adaptive search space model\n",
    "labels_train = odbo.prescreening.sp_label(X_train, Y_train, thres=threshold)\n",
    "pre_model = odbo.prescreening.XGBOD(eval_metric = 'error')\n",
    "pre_model.fit(X_train, labels_train)\n",
    "pred_labels = pre_model.predict(X_train)\n",
    "labels_test = odbo.prescreening.sp_label(X_test, Y_test, thres=threshold)\n",
    "pred_test_labels = pre_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix to check the accuracy of search space prescreening\n",
    "out_outlier, in_outlier, out_inlier, in_inlier = odbo.plot.plot_cm(labels_test, pred_test_labels, Y_test)\n",
    "print(\"Correct ratio: {0:.3%}\".format((len(out_outlier)+len(in_inlier))/len(labels_test)))\n",
    "print(\"FN ratio: {0:.3%}\".format(len(out_inlier)/len(labels_test)))\n",
    "print(\"FP ratio: {0:.3%}\".format(len(in_outlier)/len(labels_test)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster-BO with batch_size =2 for next best experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncluster_grid=[3,4,5]\n",
    "# Pick the Top 40 init experiment from the 384 experiments\n",
    "X_train_sele, Y_train_sele = torch.tensor(X_train), torch.tensor(Y_train.reshape(len(Y_train),1))\n",
    "# Only search the space after prescreening\n",
    "sele_id_test = list(np.array([k for k, x in enumerate(pred_test_labels) if x == 0]))\n",
    "X_test_sele, Y_test_sele = torch.tensor(X_test[sele_id_test, :]), torch.tensor(Y_test[sele_id_test].reshape(len(sele_id_test),1))\n",
    "search_name_sele, name_sele_temp = name[sele_id_test, :], name_sele\n",
    "\n",
    "## Run BO experiment with robust regression or directly gp\n",
    "l, search_iter = 0, 50\n",
    "batch_size = 2\n",
    "gp_method='gp_regression'\n",
    "failure_count,max_count = 0, 0\n",
    "while l < search_iter:\n",
    "    print(\"Iter: \", l, \"Current Max: \", Y_train_sele.max().detach().numpy(), \"Actual max: \",Y_test_sele.max().detach().numpy(), X_test_sele[np.argmax(Y_test_sele.detach().numpy()), :])\n",
    "    X_next, acq_value, next_exp_id = odbo.cluster_bo_design(X=X_train_sele, Y=Y_train_sele, ncluster_grid=ncluster_grid, X_pending=X_test_sele, gp_method=gp_method, batch_size=batch_size)\n",
    "    ids_keep = list(np.delete(range(X_test_sele.shape[0]), next_exp_id))\n",
    "    X_train_sele, Y_train_sele = torch.cat([X_train_sele, X_test_sele[next_exp_id, :]]), torch.cat([Y_train_sele, Y_test_sele[next_exp_id]])\n",
    "    X_test_sele, Y_test_sele, search_name_sele = X_test_sele[ids_keep, :], Y_test_sele[ids_keep], search_name_sele[ids_keep]\n",
    "    name_sele_temp = np.concatenate((name_sele_temp, search_name_sele[next_exp_id]))\n",
    "    print(\"Newly added value: \", Y_train_sele[-batch_size:].detach().numpy(), X_train_sele[-batch_size:, :])\n",
    "    feature_model1 = odbo.featurization.AvgMeasurement(raw_vars=X_train_sele, Y=Y_train_sele.detach().numpy())\n",
    "    if Y_train_sele[-batch_size:].detach().numpy().max() <= Y_train_sele[:-batch_size].max():\n",
    "        failure_count = failure_count + 1\n",
    "    else:\n",
    "        failure_count = 0\n",
    "    if failure_count >= 3 and max_count < 3:\n",
    "        max_count = max_count + 1\n",
    "        feature_model1 = odbo.featurization.MaxMeasurement(raw_vars=X_train_sele, Y=Y_train_sele.detach().numpy())\n",
    "    else:\n",
    "        max_count = 0\n",
    "    X_train_sele = torch.tensor(feature_model1.transform(X_train_sele))\n",
    "    X_test_sele= torch.tensor(feature_model1.transform(X_test_sele))\n",
    "    l = l + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster-TurBO-m for next best experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncluster_grid=[3,4,5]\n",
    "X_train_sele, Y_train_sele = torch.tensor(X_train), torch.tensor(Y_train.reshape(len(Y_train),1))\n",
    "# Only search the space after prescreening\n",
    "sele_id_test = []\n",
    "sele_id_test.extend(in_inlier)\n",
    "sele_id_test.extend(out_inlier)\n",
    "search_name_sele, name_sele_temp = name[sele_id_test, :], name_sele\n",
    "X_test_sele, Y_test_sele = torch.tensor(X_test[sele_id_test, :]), torch.tensor(Y_test[sele_id_test].reshape(len(sele_id_test),1))\n",
    "\n",
    "# Run BO experiment with robust regression or directly gp\n",
    "l, search_iter = 0, 50\n",
    "gp_method='gp_regression'\n",
    "tr_length = [4.8, 3.2]\n",
    "batch_size = 1\n",
    "failure_count = 0\n",
    "\n",
    "state = odbo.turbo.TurboState(dim=X_train_sele.shape[1], batch_size=batch_size, length=tr_length, n_trust_regions=len(tr_length), failure_tolerance = 10)\n",
    "state.best_value = Y_train_sele.max()\n",
    "while l < search_iter:\n",
    "    print(\"Iter: \", l, \"Current Max: \", Y_train_sele.max().detach().numpy(), 'TR length: ', state.length, 'True max ', Y_test_sele.max(), X_test_sele[np.argmax(Y_test_sele.detach().numpy()), :])\n",
    "    X_next, acq_value, raw_next_exp_id = odbo.cluster_turbo_design(state=state, X=X_train_sele, Y=Y_train_sele, ncluster_grid=ncluster_grid, X_pending=X_test_sele, n_trust_regions=len(tr_length), batch_size=batch_size, gp_method=gp_method)\n",
    "    Y_next_m = torch.zeros((len(tr_length), batch_size, 1), device=Y_train_sele.device, dtype=Y_train_sele.dtype)\n",
    "    next_exp_id = []\n",
    "    print(raw_next_exp_id.shape)\n",
    "    for i in range(batch_size):\n",
    "        next_exp_id_m = raw_next_exp_id[:, i]\n",
    "        Y_next_m[:, i, 0], idtoadd = Y_test_sele[next_exp_id_m].reshape(len(tr_length)), next_exp_id_m[np.argmax(Y_test_sele[next_exp_id_m])]\n",
    "        next_exp_id.append(idtoadd)\n",
    "    X_train_sele, Y_train_sele = torch.cat([X_train_sele, X_test_sele[next_exp_id, :]]), torch.cat([Y_train_sele, Y_test_sele[next_exp_id]])\n",
    "    ids_keep = list(np.delete(range(X_test_sele.shape[0]), next_exp_id))\n",
    "    X_test_sele, Y_test_sele, search_name_sele = X_test_sele[ids_keep, :], Y_test_sele[ids_keep], search_name_sele[ids_keep]\n",
    "    name_sele_temp = np.concatenate((name_sele_temp, search_name_sele[next_exp_id]))\n",
    "    print(\"Newly added value: \", Y_train_sele[-batch_size:].detach().numpy())\n",
    "    state = odbo.turbo.update_state(state=state, Y_next=Y_next_m)\n",
    "    feature_model1 = odbo.featurization.AvgMeasurement(raw_vars=X_train_sele, Y=Y_train_sele.detach().numpy())\n",
    "    if Y_train_sele[-batch_size:].detach().numpy().max() <= Y_train_sele[:-batch_size].max():\n",
    "        failure_count = failure_count + 1\n",
    "    else:\n",
    "        failure_count = 0\n",
    "    if failure_count >= 3 and max_count < 3:\n",
    "        max_count = max_count + 1\n",
    "        feature_model1 = odbo.featurization.MaxMeasurement(raw_vars=X_train_sele, Y=Y_train_sele.detach().numpy())\n",
    "    else:\n",
    "        max_count = 0\n",
    "    X_train_sele = torch.tensor(feature_model1.transform(X_train_sele))\n",
    "    X_test_sele= torch.tensor(feature_model1.transform(X_test_sele))\n",
    "\n",
    "    l = l + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
