{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import odbo\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TurBO for next best experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected initial experiments no. is  137\n",
      "Select max Y:  1.576 True max Y: 5.022\n"
     ]
    }
   ],
   "source": [
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "data_test = pd.read_csv('../datasets/GB1_2014_536944.csv', sep=',')\n",
    "name_pre, Y_test = np.array(data_test['AACombo']), np.array(data_test['Fitness'])\n",
    "\n",
    "del data_test\n",
    "if os.path.isfile('sele_indices_GB1_2014.npy') == True:\n",
    "    sele_indices = np.load('sele_indices_GB1_2014.npy')\n",
    "    shuffle_order = np.load('shuffle_order_GB1_2014.npy')\n",
    "    name_pre[1:], Y_test[1:] = name_pre[shuffle_order[1:]], Y_test[shuffle_order[1:]]\n",
    "    name = odbo.utils.code_to_array(name_pre)    \n",
    "else:\n",
    "    shuffle_order = np.arange(len(Y_test))\n",
    "    np.random.shuffle(shuffle_order[1:])\n",
    "    np.save('shuffle_order_GB1_2014.npy', shuffle_order)\n",
    "    name_pre[1:], Y_test[1:] = name_pre[shuffle_order[1:]], Y_test[shuffle_order[1:]]\n",
    "    name = odbo.utils.code_to_array(name_pre)\n",
    "    sele_indices = odbo.initialization.initial_design(name, least_occurance=np.ones(55),allow_abundance=True)\n",
    "    np.save('sele_indices_GB1_2014.npy', sele_indices)\n",
    "name_sele, Y_train = name[sele_indices, :], Y_test[sele_indices]\n",
    "ids_keep = np.delete(range(len(Y_test)), sele_indices)\n",
    "name, Y_test = name[ids_keep, :], Y_test[ids_keep]\n",
    "print('Selected initial experiments no. is ', len(Y_train))\n",
    "print('Select max Y: ', Y_train.max(), 'True max Y:', Y_test.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_selection(\n",
    "    X,\n",
    "    Y,\n",
    "    threshold=1e-4,\n",
    "    n_splits= 20,\n",
    "    test_size=0.5,\n",
    "    impurity=False,\n",
    "    feature_sele_random=None,):\n",
    "\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from collections import defaultdict\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    scores = defaultdict(list)\n",
    "    if feature_sele_random is None:\n",
    "        test_train_split = ShuffleSplit(n_splits=n_splits, test_size=test_size)\n",
    "    elif isinstance(feature_sele_random, int):\n",
    "        test_train_split = ShuffleSplit(\n",
    "            n_splits=n_splits, test_size=test_size, random_state=feature_sele_random)\n",
    "    else:\n",
    "        raise Exception(\"The specified feature_sele_random needs to be an integer.\")\n",
    "\n",
    "    for train_idx, test_idx in test_train_split.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        Y_train, Y_test = Y[train_idx].ravel(), Y[test_idx].ravel()\n",
    "        rf.fit(X_train, Y_train)\n",
    "        accuracy = r2_score(Y_test, rf.predict(X_test))\n",
    "        for i in range(X.shape[1]):\n",
    "            X_t = X_test\n",
    "            col_before_shuffle = X_t[:, i].copy()\n",
    "            np.random.shuffle(X_t[:, i])\n",
    "            shuffle_accuracy = r2_score(Y_test, rf.predict(X_t))\n",
    "            X_t[:, i] = col_before_shuffle.copy()\n",
    "            scores[i].append((accuracy - shuffle_accuracy) / accuracy)\n",
    "\n",
    "    sorted_scores = sorted(\n",
    "        [(np.mean(feature_score), feature_index) for feature_index, feature_score in scores.items()],\n",
    "        reverse=True)\n",
    "\n",
    "    k = 0\n",
    "    selected_features = []\n",
    "    importance = []\n",
    "    while sorted_scores[k][0] >= threshold:\n",
    "        selected_features.append(int(sorted_scores[k][1]))\n",
    "        importance.append(sorted_scores[k][0])\n",
    "        k = k + 1\n",
    "\n",
    "    IPR = None\n",
    "    if impurity:\n",
    "        renorm = importance / np.sum(importance)\n",
    "        IPR = 1 / np.sum([i**2 for i in renorm])\n",
    "    print(importance)\n",
    "    return selected_features, importance, IPR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature transformation done 1.4\n",
      "[14:13:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "808\n",
      "Prescreened search space size:  808\n",
      "Iter:  0 Current Max:  1.576 TR length:  [3.2] Test max:  3.359\n",
      "[['Q' 'Y' 'K' 'L' 'I' 'L' 'N' 'G' 'K' 'T' 'L' 'K' 'G' 'E' 'T' 'T' 'T' 'E'\n",
      "  'A' 'V' 'D' 'T' 'A' 'T' 'A' 'E' 'K' 'V' 'F' 'K' 'L' 'Y' 'A' 'N' 'D' 'N'\n",
      "  'G' 'V' 'D' 'G' 'E' 'W' 'T' 'Y' 'D' 'D' 'A' 'T' 'K' 'T' 'F' 'T' 'V' 'T'\n",
      "  'E']]\n",
      "Newly added value:  [[0.961]] ['Q' 'Y' 'K' 'L' 'I' 'L' 'N' 'G' 'K' 'T' 'L' 'K' 'G' 'E' 'T' 'T' 'T' 'E'\n",
      " 'A' 'V' 'D' 'T' 'A' 'T' 'A' 'E' 'K' 'V' 'F' 'K' 'L' 'Y' 'A' 'N' 'D' 'N'\n",
      " 'G' 'V' 'D' 'G' 'E' 'W' 'T' 'Y' 'D' 'D' 'A' 'T' 'K' 'T' 'F' 'T' 'V' 'T'\n",
      " 'E'] Current size:  138\n",
      "Feature transformation done 1.4\n",
      "[14:20:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l, search_iter = 0, 50\n",
    "gp_method='gp_regression'\n",
    "tr_length = [3.2]\n",
    "batch_size = 1\n",
    "failure_count,max_count = 0,0\n",
    "state = odbo.turbo.TurboState(dim=55, batch_size=batch_size, length=tr_length, n_trust_regions=len(tr_length), failure_tolerance = 10)\n",
    "state.best_value = Y_train.max()\n",
    "\n",
    "name_sele_temp = np.array(name_sele).copy()\n",
    "search_name = np.array(name).copy()\n",
    "Y_train_sele = torch.tensor(Y_train.reshape(len(Y_train),1))\n",
    "\n",
    "while l < search_iter:\n",
    "    if Y_train_sele[-batch_size:].detach().numpy().max() < Y_train_sele[:-batch_size].max():\n",
    "        failure_count = failure_count + 1\n",
    "        feature_model = odbo.featurization.MeasurementFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Max', mode='rank_assist')\n",
    "    else:\n",
    "        failure_count = 0\n",
    "        feature_model = odbo.featurization.MeasurementFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Max', mode='rank_assist')\n",
    "    if failure_count >= 3 and max_count < 3:\n",
    "        max_count = max_count + 1\n",
    "        feature_model = odbo.featurization.MeasurementFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Avg', mode='rank_assist')\n",
    "    else:\n",
    "        max_count = 0\n",
    "        feature_model = odbo.featurization.MeasurementFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method='Avg', mode='rank_assist')\n",
    "\n",
    "    X_test_trans= feature_model.transform(search_name)\n",
    "    X_train_sele_trans = feature_model.transform(name_sele_temp)\n",
    "    X_test_trans, X_train_sele_trans = torch.tensor(X_test_trans), torch.tensor(X_train_sele_trans)\n",
    "    threshold = 1.4\n",
    "    print('Feature transformation done', threshold)\n",
    "\n",
    "    labels_train = odbo.prescreening.sp_label(X_train_sele_trans, Y_train_sele, thres=threshold)\n",
    "    pre_model = odbo.prescreening.XGBOD(eval_metric = 'error')\n",
    "    pre_model.fit(X_train_sele_trans, labels_train)\n",
    "    pred_test_labels = pre_model.predict(X_test_trans)\n",
    "    sele_id_test = list(np.where(pred_test_labels == 0)[0])\n",
    "    del pre_model, pred_test_labels, feature_model\n",
    "    gc.collect()\n",
    "    \n",
    "    print(len(sele_id_test))\n",
    "    if len(sele_id_test) >= 50000:\n",
    "        threshold =  min(2.0, Y_train_sele[np.argsort(Y_train_sele)[int(0.99*len(Y_train_sele))]])\n",
    "        labels_train = odbo.prescreening.sp_label(X_train_sele_trans, Y_train_sele, thres=threshold)\n",
    "        pre_model = odbo.prescreening.XGBOD(eval_metric = 'error')\n",
    "        pre_model.fit(X_train_sele_trans, labels_train)\n",
    "        pred_test_labels = pre_model.predict(X_test_trans)\n",
    "        sele_id_test = list(np.where(pred_test_labels == 0)[0])\n",
    "    elif len(sele_id_test) <= 100:\n",
    "        threshold = Y_train_sele[np.argsort(Y_train_sele)[int(0.99*len(Y_train_sele))]]\n",
    "        labels_train = odbo.prescreening.sp_label(X_train_sele_trans, Y_train_sele, thres=threshold)\n",
    "        pre_model = odbo.prescreening.XGBOD(eval_metric = 'error')\n",
    "        pre_model.fit(X_train_sele_trans, labels_train)\n",
    "        pred_test_labels = pre_model.predict(X_test_trans)\n",
    "        sele_id_test = list(np.where(pred_test_labels == 0)[0])\n",
    "\n",
    "    selected_features = []\n",
    "    for i in range(X_train_sele_trans.shape[1]):\n",
    "        if (X_train_sele_trans[:, i]-X_train_sele_trans[0,i]).any() !=0:\n",
    "            selected_features.append(i)\n",
    "#     selected_features, importance, IPR = rf_feature_selection(X=X_train_sele_trans.numpy(), Y=Y_train_sele.numpy())\n",
    "#     print(len(selected_features))\n",
    "    X_test_trans, X_train_sele_trans = X_test_trans[:, selected_features], X_train_sele_trans[:, selected_features]\n",
    "            \n",
    "    print('Prescreened search space size: ', len(sele_id_test))\n",
    "    search_name_sele = search_name[sele_id_test, :]\n",
    "    X_test_sele_trans, Y_test_sele = torch.tensor(X_test_trans[sele_id_test, :]), torch.tensor(Y_test[sele_id_test].reshape(len(sele_id_test),1))\n",
    "    print(\"Iter: \", l, \"Current Max: \", Y_train_sele.max().detach().numpy(), 'TR length: ', state.length, \"Test max: \", Y_test_sele.max().detach().numpy())\n",
    "    X_next, acq_value, raw_next_exp_id = odbo.turbo_design(state=state, X=X_train_sele_trans, Y=Y_train_sele, X_pending=X_test_sele_trans, n_trust_regions=len(tr_length), batch_size=batch_size, gp_method=gp_method)\n",
    "    Y_next_m = torch.zeros((len(tr_length), batch_size, 1), device=Y_train_sele.device, dtype=Y_train_sele.dtype)\n",
    "    next_exp_id = []\n",
    "    for i in range(batch_size):\n",
    "        next_exp_id_m = raw_next_exp_id[:, i]\n",
    "        Y_next_m[:, i, 0], idtoadd = Y_test_sele[next_exp_id_m].reshape(len(tr_length)), next_exp_id_m[np.argmax(Y_test_sele[next_exp_id_m])]\n",
    "        next_exp_id.append(idtoadd)\n",
    "    Y_train_sele = torch.cat([Y_train_sele, Y_test_sele[next_exp_id]])\n",
    "    name_sele_temp = np.concatenate((name_sele_temp, search_name_sele[next_exp_id]))\n",
    "    print(search_name[np.array(sele_id_test)[next_exp_id]])\n",
    "    ids_keep = np.delete(range(len(search_name)), np.array(sele_id_test)[next_exp_id])\n",
    "    search_name = search_name[ids_keep]\n",
    "    print(\"Newly added value: \", Y_train_sele[-batch_size:].detach().numpy(), name_sele_temp[-1], \"Current size: \", len(Y_train_sele))\n",
    "    state = odbo.turbo.update_state(state=state, Y_next=Y_next_m)\n",
    "    l = l + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
