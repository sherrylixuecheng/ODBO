{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different featurizations with different dimensions\n",
    "GB1_2016 has combintorially measured all the possible mutations and been studied extensively in the previous literature. Here, we use GB1_2016 as an example to explore many different possible settings in ODBO and collect the corresponding results. We will walk through this notebook with detailed comments.\n",
    "To use this notebook, please change the global control varibles and read the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import odbo\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global control varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment settings \n",
    "dataset_name ='GB1_2016'\n",
    "random_seed = 0 #Random seed for the trial\n",
    "search_iter = 50 #Number of new observations, GB1_2014=100, BRCA1=50, avGFP_2016=50\n",
    "encoding = 'georgiev'\n",
    "if encoding == 'onehot':\n",
    "    index_data = np.load('example_protein_onehot_IndexToCombo.npy')\n",
    "    feature_data = np.load('example_protein_onehot_UnNormalized.npy').reshape(160000,80)\n",
    "elif encoding == 'georgiev':\n",
    "    index_data = np.load('example_protein_georgiev_IndexToCombo.npy')\n",
    "    feature_data = np.load('example_protein_georgiev_Normalized.npy').reshape(160000,76)\n",
    "    \n",
    "# BO method settings (Optimization step)\n",
    "BO_method = 'TuRBO' #Must be 'BO' or 'TuRBO'\n",
    "gp_method='gp_regression' #Must be 'gp_regression' or 'robust_regression'\n",
    "acqfn = 'ei'\n",
    "tr_length = [6.4] #Trust region length, used in the TuRBO. \n",
    "batch_size = 1 #Number of new oberservations provided by BO. We found 1 is the most cost-effective experimentally\n",
    "failure_tolerance =10 #Number of failure iterations to change TR length in TuRBO\n",
    "save_files = True #Save files or not\n",
    "np.random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_test = pd.read_csv('../datasets/GB1_2016_149361.csv', sep=',')\n",
    "name, Y_test = np.array(data_test['AACombo']), np.array(data_test['Fitness'])\n",
    "#Load the preselected indices using a certain shuffling order. Control Round 0 experiments to be the same for different trials\n",
    "if os.path.isfile('sele_experiment_GB1_2016.npy') == True:\n",
    "    name_sele = np.load('sele_experiment_GB1_2016.npy')\n",
    "    Y_train = np.load('sele_fitness_GB1_2016.npy')\n",
    "else:\n",
    "    # Let each site has 20 AA codes at least show up twice \n",
    "    sele_indices = odbo.initialization.initial_design(name, least_occurance=2*np.ones(name.shape[1]),allow_abundance=allow_abundance, update_method=update_method,verbose = True)\n",
    "    # Initial experiments are selected to be name_sele with fitness of Y_sele\n",
    "    name_sele, Y_train = name[sele_indices], Y_test[sele_indices]\n",
    "print('Selected initial experiments no. is ', len(Y_train))\n",
    "print('Select max Y: ', Y_train.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indice = []\n",
    "fullname = []\n",
    "for i in range(40):\n",
    "    fullname.append(''.join(name_sele[i, :]))\n",
    "fullname = np.array(fullname)\n",
    "for i in range(name.shape[0]):\n",
    "    a = np.where(name[i] == fullname)[0]\n",
    "    if len(a) == 0 :\n",
    "        test_indice.append(i)\n",
    "name = name[test_indice]\n",
    "Y_test = Y_test[test_indice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization and find the adaptive search space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Featurization and find the adaptive search space model\n",
    "X_train, X_test = [],[]\n",
    "for i in range(name_sele.shape[0]):\n",
    "    a = np.where(''.join(name_sele[i, :])==index_data)[0][0]\n",
    "    X_train.append(feature_data[a])\n",
    "X_train = np.vstack(X_train)\n",
    "for i in range(name.shape[0]):\n",
    "    a = np.where(''.join(name[i])==index_data)[0][0]\n",
    "    X_test.append(feature_data[a])\n",
    "X_test = np.vstack(X_test)\n",
    "print(X_train.shape, X_test.shape)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('X_train.npy', X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creat search data\n",
    "# shuffle_order = np.arange(len(Y_test))\n",
    "np.random.shuffle(shuffle_order)\n",
    "X_test = X_test[shuffle_order]\n",
    "Y_test = Y_test[shuffle_order]\n",
    "X_train_sele, Y_train_sele = torch.tensor(X_train), torch.tensor(Y_train.reshape(len(Y_train),1))\n",
    "X_test_sele, Y_test_sele = torch.tensor(X_test), torch.tensor(Y_test.reshape(len(Y_test),1))\n",
    "print(X_train_sele.shape, X_test_sele.shape)\n",
    "## Run BO experiment with robust regression or directly gp\n",
    "l, failure_count = 0, 0 #l is the current iteration, failure_count controls when to switch to another featurization\n",
    "if BO_method == 'TuRBO':\n",
    "    state = odbo.turbo.TurboState(dim=X_train_sele.shape[1], batch_size=batch_size, length=tr_length, n_trust_regions=len(tr_length), failure_tolerance = failure_tolerance)\n",
    "    state.best_value = Y_train_sele.max()\n",
    "\n",
    "while l < search_iter:\n",
    "    print(\"Iter: \", l, \"Current Max: \", Y_train_sele.max().detach().numpy(), \"Test max: \", Y_test_sele.max().detach().numpy())\n",
    "    active_space = []\n",
    "    for j in range(X_train_sele.shape[1]):\n",
    "        a=np.where(X_train_sele[0, j] == X_train_sele[1:, j])[0]\n",
    "        if len(a) != len(X_train_sele)-1:\n",
    "            active_space.append(j)\n",
    "    print(len(active_space))\n",
    "    X_train_sele_active = X_train_sele[:, active_space]\n",
    "        \n",
    "    # Run optimization using different methods    \n",
    "    if BO_method == 'BO':\n",
    "        X_next, acq_value, next_exp_id = odbo.bo_design(X=X_train_sele_active, Y=Y_train_sele, X_pending=X_test_sele, gp_method=gp_method, batch_size=batch_size, acqfn=acqfn)\n",
    "    elif BO_method == 'TuRBO':\n",
    "        X_next, acq_value, raw_next_exp_id = odbo.turbo_design(state=state, X=X_train_sele_active, Y=Y_train_sele, X_pending=X_test_sele, n_trust_regions=len(tr_length), batch_size=batch_size, gp_method=gp_method, acqfn=acqfn)\n",
    "        Y_next_m = torch.zeros((len(tr_length), batch_size, 1), device=Y_train_sele.device, dtype=Y_train_sele.dtype)\n",
    "        next_exp_id = []  \n",
    "        for i in range(batch_size):\n",
    "            next_exp_id_m = raw_next_exp_id[:, i]\n",
    "            Y_next_m[:, i, 0], idtoadd = Y_test_sele[next_exp_id_m].reshape(len(tr_length)), next_exp_id_m[np.argmax(Y_test_sele[next_exp_id_m])]\n",
    "            next_exp_id.append(idtoadd)\n",
    "    # Update the newly find experimental value to the current training set, and remove that point from test set\n",
    "    Y_train_sele = torch.cat([Y_train_sele, Y_test_sele[next_exp_id]])\n",
    "    ids_keep = list(np.delete(range(Y_test_sele.shape[0]), next_exp_id))\n",
    "    Y_test_sele = Y_test_sele[ids_keep]\n",
    "    X_train_sele = torch.cat((X_train_sele, X_test_sele[next_exp_id]))\n",
    "    X_test_sele = X_test_sele[ids_keep]\n",
    "    print(\"Newly added value: \", Y_train_sele[-batch_size:].detach().numpy())\n",
    "    l = l+1\n",
    "\n",
    "# Save the BO results. Note we save all the observations including the Round 0 ones\n",
    "if save_files:\n",
    "    if acqfn == 'ei':\n",
    "        if gp_method == 'robust_regression':\n",
    "            np.save('results/{}/{}_{}_RobustGP_batch{}_{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, encoding, random_seed), Y_train_sele)\n",
    "        elif gp_method == 'gp_regression':\n",
    "            np.save('results/{}/{}_{}_GP_batch{}_{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, encoding, random_seed), Y_train_sele)\n",
    "    else:\n",
    "        if gp_method == 'robust_regression':\n",
    "            np.save('results/{}/{}_{}_RobustGP_batch{}_{}_{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, encoding, acqfn, random_seed), Y_train_sele)\n",
    "        elif gp_method == 'gp_regression':\n",
    "            np.save('results/{}/{}_{}_GP_batch{}_{}_{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, encoding, acqfn, random_seed), Y_train_sele)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
